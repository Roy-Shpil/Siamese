{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Imports",
   "id": "9f358593acccf78f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T15:41:32.886647Z",
     "start_time": "2025-05-26T15:41:32.810763Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from utils.general_utils import load_data, load_files, study_best_params\n",
    "from utils.nn_utils import train_model_nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nn_utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgeneral_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_data, load_files, study_best_params\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_model_nn\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Roy\\Army\\Hacshara\\Siamese\\Siamese\\code\\prediction\\utils\\general_utils.py:6\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Any\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m KFold\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnn_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_model_nn\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01moptuna\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'nn_utils'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Loads",
   "id": "89c8d59c7857fdd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1. Loading train and test filepaths and labels",
   "id": "fd122387415ccec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:40:52.962695Z",
     "start_time": "2025-05-26T15:02:41.166655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_data = load_files()\n",
    "train_val_set_1, train_val_set_2 = load_data(processed_data, 'train')\n",
    "train_val_labels = torch.Tensor(processed_data['train_labels']).reshape(-1,1)\n",
    "test_labels = torch.Tensor(processed_data['test_labels']).reshape(-1,1)"
   ],
   "id": "bd1f9ee8cdfa5205",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:40:52.967441100Z",
     "start_time": "2025-05-26T15:02:48.227794Z"
    }
   },
   "cell_type": "code",
   "source": "test_set_1, test_set_2 = load_data(processed_data, 'train')",
   "id": "3b2cb0fae63c2158",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:40:52.970438700Z",
     "start_time": "2025-05-26T15:02:54.748867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "names_to_save = ['train_val_set_1', 'train_val_set_2', 'test_set_1', 'test_set_2', 'train_val_labels', 'test_labels']\n",
    "vars_to_save = [train_val_set_1, train_val_set_2, test_set_1, test_set_2, train_val_labels, test_labels]\n",
    "for i, name in enumerate(names_to_save):\n",
    "    with open(f'../../data/to_colab/{name}', 'wb') as f:\n",
    "        pickle.dump(vars_to_save[i], f)"
   ],
   "id": "b1bf7b8e670eb12",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/to_colab/train_val_set_1'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m vars_to_save = [train_val_set_1, train_val_set_2, test_set_1, test_set_2, train_val_labels, test_labels]\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(names_to_save):\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m../../data/to_colab/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mname\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mwb\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m      6\u001B[39m         pickle.dump(vars_to_save[i], f)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Roy\\Army\\Hacshara\\Siamese\\Siamese\\venv\\Scripts\\python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    321\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    322\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    323\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    324\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m326\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '../../data/to_colab/train_val_set_1'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:40:52.971438Z",
     "start_time": "2025-05-26T15:07:35.969756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    'batch_size': {'suggestion': 'categorical', 'options': [32, 64, 128], 'listed': None},\n",
    "    'activation': {'suggestion': 'categorical', 'options': [\"ReLU\", \"leaky_relu\", \"GELU\", \"ELU\"], 'listed': None},\n",
    "    'scheduler': {'suggestion': 'categorical', 'options': [\"linear\", \"cosine\", \"plateau\"], 'listed': None},\n",
    "    'num_epochs': {'suggestion': 'int', 'low': 20, 'high': 200, 'log': False, 'listed': None},\n",
    "    'learning_rate': {'suggestion': 'float', 'low': 1e-6, 'high': 1e-2, 'log': True, 'listed': None},\n",
    "    'num_convs': {'suggestion': 'int', 'low': 1, 'high': 10, 'log': False, 'listed': None},\n",
    "    'channels': {'suggestion': 'int', 'low': 4, 'high': 512, 'log': True, 'listed': 'num_convs'},\n",
    "    'kernel_size': {'suggestion': 'categorical', 'options': [3, 5, 7], 'listed': 'num_convs'}\n",
    "}\n",
    "\n",
    "params_initial = {\n",
    "    'batch_size': 128,\n",
    "    'activation': 'ReLU',\n",
    "    'scheduler': \"cosine\",\n",
    "    'num_epochs': 20,\n",
    "    'learning_rate': 3e-6,\n",
    "    'num_convs': 5,\n",
    "    'channels': [32, 64, 128, 128, 256],\n",
    "    'kernel_size': [11, 6, 4, 4, 3]\n",
    "}\n",
    "\n",
    "params_trash = {\n",
    "    'batch_size': 16,\n",
    "    'activation': 'ReLU',\n",
    "    'scheduler': \"cosine\",\n",
    "    'num_epochs': 1,\n",
    "    'learning_rate': 3e-6,\n",
    "    'num_convs': 5,\n",
    "    'channels': [1, 1, 1, 1, 1],\n",
    "    'kernel_size': [5, 5, 5, 5, 5]\n",
    "}"
   ],
   "id": "47fb7ef0fb95e521",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:40:52.973662400Z",
     "start_time": "2025-05-26T15:05:08.992193Z"
    }
   },
   "cell_type": "code",
   "source": "train_1, val_1, train_2, val_2, train_out, val_out = train_test_split(train_val_set_1, train_val_set_2, train_val_labels, test_size=0.2, random_state=42)\n",
   "id": "fcf181aa7aa4df3d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:13:11.700544Z",
     "start_time": "2025-05-26T15:12:36.272114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_loss, model, scaler = train_model_nn(train_1, train_2, train_out, val_1, val_2, val_out, params_trash, check_val=True)\n",
    "print(\"wtg\")"
   ],
   "id": "bed8d33e8dc958ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1 out of 110. loss: 0.6267149448394775\n",
      "batch: 2 out of 110. loss: 0.7028146982192993\n",
      "batch: 3 out of 110. loss: 0.6819623112678528\n",
      "batch: 4 out of 110. loss: 0.6955137252807617\n",
      "batch: 5 out of 110. loss: 0.6770185828208923\n",
      "batch: 6 out of 110. loss: 0.6625450253486633\n",
      "batch: 7 out of 110. loss: 0.6719553470611572\n",
      "batch: 8 out of 110. loss: 0.6864761710166931\n",
      "batch: 9 out of 110. loss: 0.7069273591041565\n",
      "batch: 10 out of 110. loss: 0.6761548519134521\n",
      "batch: 11 out of 110. loss: 0.7457292079925537\n",
      "batch: 12 out of 110. loss: 0.7570791840553284\n",
      "batch: 13 out of 110. loss: 0.7291197180747986\n",
      "batch: 14 out of 110. loss: 0.6709833741188049\n",
      "batch: 15 out of 110. loss: 0.7635343670845032\n",
      "batch: 16 out of 110. loss: 0.7170146107673645\n",
      "batch: 17 out of 110. loss: 0.6665943264961243\n",
      "batch: 18 out of 110. loss: 0.6659433841705322\n",
      "batch: 19 out of 110. loss: 0.680923342704773\n",
      "batch: 20 out of 110. loss: 0.6697547435760498\n",
      "batch: 21 out of 110. loss: 0.7030714750289917\n",
      "batch: 22 out of 110. loss: 0.6774473190307617\n",
      "batch: 23 out of 110. loss: 0.7950225472450256\n",
      "batch: 24 out of 110. loss: 0.6771596670150757\n",
      "batch: 25 out of 110. loss: 0.7256971001625061\n",
      "batch: 26 out of 110. loss: 0.8125357031822205\n",
      "batch: 27 out of 110. loss: 0.6971692442893982\n",
      "batch: 28 out of 110. loss: 0.7520171403884888\n",
      "batch: 29 out of 110. loss: 0.6480004191398621\n",
      "batch: 30 out of 110. loss: 0.8682884573936462\n",
      "batch: 31 out of 110. loss: 0.7294471859931946\n",
      "batch: 32 out of 110. loss: 0.6963605284690857\n",
      "batch: 33 out of 110. loss: 0.6942897439002991\n",
      "batch: 34 out of 110. loss: 0.7114025354385376\n",
      "batch: 35 out of 110. loss: 0.7631239891052246\n",
      "batch: 36 out of 110. loss: 0.6438862681388855\n",
      "batch: 37 out of 110. loss: 0.7087694406509399\n",
      "batch: 38 out of 110. loss: 0.631632924079895\n",
      "batch: 39 out of 110. loss: 0.7153346538543701\n",
      "batch: 40 out of 110. loss: 0.7558631300926208\n",
      "batch: 41 out of 110. loss: 0.742676317691803\n",
      "batch: 42 out of 110. loss: 0.6983236074447632\n",
      "batch: 43 out of 110. loss: 0.6567422151565552\n",
      "batch: 44 out of 110. loss: 0.7668364644050598\n",
      "batch: 45 out of 110. loss: 0.7300840616226196\n",
      "batch: 46 out of 110. loss: 0.6935122609138489\n",
      "batch: 47 out of 110. loss: 0.7073882222175598\n",
      "batch: 48 out of 110. loss: 0.7407321333885193\n",
      "batch: 49 out of 110. loss: 0.6781227588653564\n",
      "batch: 50 out of 110. loss: 0.7285211682319641\n",
      "batch: 51 out of 110. loss: 0.7289668917655945\n",
      "batch: 52 out of 110. loss: 0.6386520862579346\n",
      "batch: 53 out of 110. loss: 0.7174803614616394\n",
      "batch: 54 out of 110. loss: 0.6698652505874634\n",
      "batch: 55 out of 110. loss: 0.769330620765686\n",
      "batch: 56 out of 110. loss: 0.7330436706542969\n",
      "batch: 57 out of 110. loss: 0.7147114872932434\n",
      "batch: 58 out of 110. loss: 0.690418004989624\n",
      "batch: 59 out of 110. loss: 0.682345986366272\n",
      "batch: 60 out of 110. loss: 0.7079495191574097\n",
      "batch: 61 out of 110. loss: 0.7620908617973328\n",
      "batch: 62 out of 110. loss: 0.6661344766616821\n",
      "batch: 63 out of 110. loss: 0.7191686630249023\n",
      "batch: 64 out of 110. loss: 0.6619153618812561\n",
      "batch: 65 out of 110. loss: 0.6484737396240234\n",
      "batch: 66 out of 110. loss: 0.9457522630691528\n",
      "batch: 67 out of 110. loss: 0.7249117493629456\n",
      "batch: 68 out of 110. loss: 0.6643746495246887\n",
      "batch: 69 out of 110. loss: 0.5879364013671875\n",
      "batch: 70 out of 110. loss: 0.718109667301178\n",
      "batch: 71 out of 110. loss: 0.6833342909812927\n",
      "batch: 72 out of 110. loss: 0.6935896873474121\n",
      "batch: 73 out of 110. loss: 0.717312753200531\n",
      "batch: 74 out of 110. loss: 0.7597501873970032\n",
      "batch: 75 out of 110. loss: 0.7232065200805664\n",
      "batch: 76 out of 110. loss: 0.6718414425849915\n",
      "batch: 77 out of 110. loss: 0.7309472560882568\n",
      "batch: 78 out of 110. loss: 0.8095672130584717\n",
      "batch: 79 out of 110. loss: 0.7234522104263306\n",
      "batch: 80 out of 110. loss: 0.7181021571159363\n",
      "batch: 81 out of 110. loss: 0.7333923578262329\n",
      "batch: 82 out of 110. loss: 0.7024379968643188\n",
      "batch: 83 out of 110. loss: 0.7253435850143433\n",
      "batch: 84 out of 110. loss: 0.6704466938972473\n",
      "batch: 85 out of 110. loss: 0.7944100499153137\n",
      "batch: 86 out of 110. loss: 0.6812452673912048\n",
      "batch: 87 out of 110. loss: 0.7408044338226318\n",
      "batch: 88 out of 110. loss: 0.7369068264961243\n",
      "batch: 89 out of 110. loss: 0.7673517465591431\n",
      "batch: 90 out of 110. loss: 0.6140536665916443\n",
      "batch: 91 out of 110. loss: 0.7689432501792908\n",
      "batch: 92 out of 110. loss: 0.801267147064209\n",
      "batch: 93 out of 110. loss: 0.6110036373138428\n",
      "batch: 94 out of 110. loss: 0.693098247051239\n",
      "batch: 95 out of 110. loss: 0.7168591618537903\n",
      "batch: 96 out of 110. loss: 0.702675461769104\n",
      "batch: 97 out of 110. loss: 0.7307095527648926\n",
      "batch: 98 out of 110. loss: 0.6992009878158569\n",
      "batch: 99 out of 110. loss: 0.6995680332183838\n",
      "batch: 100 out of 110. loss: 0.7571575045585632\n",
      "batch: 101 out of 110. loss: 0.7226957082748413\n",
      "batch: 102 out of 110. loss: 0.7128866314888\n",
      "batch: 103 out of 110. loss: 0.669850766658783\n",
      "batch: 104 out of 110. loss: 0.6550544500350952\n",
      "batch: 105 out of 110. loss: 0.6621602773666382\n",
      "batch: 106 out of 110. loss: 0.6915948987007141\n",
      "batch: 107 out of 110. loss: 0.8027133941650391\n",
      "batch: 108 out of 110. loss: 0.6633838415145874\n",
      "batch: 109 out of 110. loss: 0.6648152470588684\n",
      "batch: 110 out of 110. loss: 0.7042639255523682\n",
      "epoch: 0, loss: 0.7098477103493429, val_loss: 0.7056757807731628\n",
      "wtg\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:13:13.191697Z",
     "start_time": "2025-05-26T15:13:13.164695Z"
    }
   },
   "cell_type": "code",
   "source": "val_loss",
   "id": "cce9633c75304a20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.7056758)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60edaa85ed94c109"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
